{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256221b4-e649-420d-a92b-efd3169d83bb",
   "metadata": {},
   "source": [
    "# RAG System - Baseline and Transformation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99facfd3-9db1-477b-914a-1ccd14d92181",
   "metadata": {},
   "source": [
    "## Libraries and Conifguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e94ed050-e3f5-41fc-ac54-763a21d6b007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emir\\Documents\\Training\\VS Code\\Master-Arbeit\\master-thesis\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import openai\n",
    "import os\n",
    "import nltk\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import faiss\n",
    "import time\n",
    "from rouge import Rouge\n",
    "from typing import List, Optional, Union, Dict\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from llmlingua import PromptCompressor\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fbbe3f0-6cc0-44fc-a311-2d83cadff218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Version: 12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c49a167a-335d-4523-ba3a-2d47b35e2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Get OpenAI Key\n",
    "SECRET_KEY = os.environ.get(\"OPENAI_KEY\")\n",
    "os.environ['OPENAI_API_KEY'] = SECRET_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c7b9ec-f712-4f54-9afc-d14dcc853129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Emir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Suppress httpx INFO logs\n",
    "# logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "# Ensure NLTK's punkt tokenizer is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Base directory paths\n",
    "BASE_DATA_PATH = os.path.join('..', 'data', 'cleaned')\n",
    "BASE_INDEX_PATH = os.path.join('..', 'models', 'embeddings')\n",
    "\n",
    "# Sector-specific configurations\n",
    "SECTORS = {\n",
    "    'education': {\n",
    "        'dataset_path': os.path.join(BASE_DATA_PATH, 'squad', 'squad_train-v2.0_with_topics.json'),\n",
    "        'dataset_test': os.path.join('data', 'education', 'splits', 'education_test.csv'),\n",
    "        'default_index_path': os.path.join(BASE_INDEX_PATH, 'squad_faiss_index_new.idx'),\n",
    "        'embedding_model': 'all-mpnet-base-v2',\n",
    "        'prompt_prefix': \"Answer the following educational question based on the provided context. Provide only a single, concise word or short phrase as the answer without any additional explanation or context.\\n\\nQuestion: What was the name of Shen Fu's memoir?\\nAnswer: Six Chapters of a Floating Life\\n\\nQuestion: What became more common during the Baroque era?\\nAnswer: vocal forms\",\n",
    "        'prompt_eval_prefix': \"As an expert evaluator, compare the following generated answer with the ground truth\",\n",
    "        'context_column': 'context',\n",
    "        'question_category': 'question_class',\n",
    "        'answer_truth': 'answers',\n",
    "        'file_type': 'json',\n",
    "        'hyperparameters': {\n",
    "            'batch_size': 5,\n",
    "            'max_retries': 5,\n",
    "            'initial_delay': 1,\n",
    "            'temperature': 1.0,\n",
    "            'k': 7,\n",
    "            'top_p': 0.86\n",
    "        }\n",
    "    },\n",
    "    'healthcare': {\n",
    "        'dataset_path': os.path.join(BASE_DATA_PATH, 'pubmedqa', 'pubmedqa_cleaned_topics_subset.csv'),\n",
    "        'dataset_test': os.path.join('data', 'healthcare', 'splits', 'healthcare_test.csv'),\n",
    "        'default_index_path': os.path.join(BASE_INDEX_PATH, 'pubmedqa_faiss_index_subset.idx'),\n",
    "        'embedding_model': 'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb',\n",
    "        'prompt_prefix': \"Answer the following medical question based on the provided context. Please provide a concise and direct answer.\",\n",
    "        'prompt_eval_prefix': \"You are a healthcare expert in evaluating AI-generated healthcare answers compared with their ground truth\",\n",
    "        'context_column': 'context',\n",
    "        'answer_truth': 'answer',\n",
    "        'file_type': 'csv',\n",
    "        'hyperparameters': {\n",
    "            'batch_size': 5,\n",
    "            'max_retries': 5,\n",
    "            'initial_delay': 1,\n",
    "            'temperature': 0.59,\n",
    "            'k': 7,\n",
    "            'top_p': 0.57\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c2f685-59ec-4c9d-a7ca-1a1c608f23f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created missing folder: data/education/processed/\n",
      "Created missing folder: data/healthcare/processed/\n"
     ]
    }
   ],
   "source": [
    "# Create folders\n",
    "required_folders = [\n",
    "    'data/education/processed/',\n",
    "    'data/healthcare/processed/'\n",
    "]\n",
    "\n",
    "for folder in required_folders:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        print(f\"Created missing folder: {folder}\")\n",
    "    else:\n",
    "        print(f\"Folder exists: {folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36632e-0d18-4cdf-9fdc-cdd90830d0c3",
   "metadata": {},
   "source": [
    "## RAG Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fbb05a-d801-4fd4-b454-eb0c9b3134e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryTransformationType(Enum):\n",
    "    NONE = \"none\"\n",
    "    BASELINE = \"baseline\"\n",
    "    COOKBOOK = \"cookbook\"\n",
    "    HYDE = \"hyde\"\n",
    "    COMPRESSION = \"compression\"\n",
    "\n",
    "class RAGSystem:\n",
    "    def __init__(self, sector_config, hyperparameters, questions_df, faiss_index_path=None, transformation_type=QueryTransformationType.NONE, model_name='gpt-4o'):\n",
    "        self.dataset_test = sector_config['dataset_test']\n",
    "        self.dataset_path = sector_config['dataset_path']\n",
    "        self.file_type = sector_config.get('file_type', 'json')\n",
    "        self.context_column = sector_config.get('context_column', 'context')\n",
    "        self.question_column = sector_config.get('question_column', 'question')\n",
    "        self.answer_column = 'generated_answer'\n",
    "        self.answer_truth = sector_config.get('answer_truth', 'answer')\n",
    "        self.index_path = faiss_index_path if faiss_index_path else sector_config['default_index_path']\n",
    "        self.embedding_model_name = sector_config['embedding_model']\n",
    "        self.prompt_prefix = sector_config['prompt_prefix']\n",
    "        self.prompt_eval_prefix = sector_config['prompt_eval_prefix']\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.temperature = hyperparameters.get('temperature', 0.7)\n",
    "        self.k = hyperparameters.get('k', 5)\n",
    "        self.top_p = hyperparameters.get('top_p', 0.5)\n",
    "        self.batch_size = hyperparameters.get('batch_size', 5)\n",
    "        self.max_retries = hyperparameters.get('max_retries', 5)\n",
    "        self.initial_delay = hyperparameters.get('initial_delay', 1)\n",
    "\n",
    "        # Query transformation settings\n",
    "        if isinstance(transformation_type, str):\n",
    "            transformation_type = QueryTransformationType[transformation_type.upper()]\n",
    "        self.transformation_type = transformation_type\n",
    "        \n",
    "        # Initialize models\n",
    "        self.embedding_model = SentenceTransformer(self.embedding_model_name)\n",
    "        self.contexts = self._load_contexts()\n",
    "        self.index = self._load_faiss_index()\n",
    "        self.questions_df = questions_df.copy()\n",
    "        self.model_llm = model_name\n",
    "        \n",
    "        # Initialize query transformer if needed\n",
    "        self.query_transformer = self._initialize_transformer()\n",
    "\n",
    "    def _initialize_transformer(self):\n",
    "        \"\"\"Initialize the appropriate query transformer based on transformation type.\"\"\"\n",
    "        if self.transformation_type == QueryTransformationType.NONE:\n",
    "            return None\n",
    "\n",
    "        # Initialize model that is used for transformation\n",
    "        client = openai.OpenAI()\n",
    "        return QueryTransformer(client)\n",
    "\n",
    "       \n",
    "    def _load_contexts(self):\n",
    "        if not os.path.exists(self.dataset_path):\n",
    "            raise FileNotFoundError(f\"Dataset not found at {self.dataset_path}\")\n",
    "\n",
    "        if self.file_type.lower() == 'json':\n",
    "            data = pd.read_json(self.dataset_path, orient='records', lines=True)\n",
    "        elif self.file_type.lower() == 'csv':\n",
    "            data = pd.read_csv(self.dataset_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {self.file_type}\")\n",
    "\n",
    "        if self.context_column not in data.columns:\n",
    "            raise ValueError(f\"Context column '{self.context_column}' not found in the dataset.\")\n",
    "\n",
    "        contexts = data[self.context_column].dropna().unique().tolist()\n",
    "        return contexts\n",
    "\n",
    "    def _load_faiss_index(self):\n",
    "        if not os.path.exists(self.index_path):\n",
    "            raise FileNotFoundError(f\"FAISS index not found at {self.index_path}. Please ensure the index is created.\")\n",
    "        \n",
    "        print(f\"Loading FAISS index from {self.index_path}...\")\n",
    "        index = faiss.read_index(self.index_path)\n",
    "        return index\n",
    "\n",
    "    def transform_query(self, query: str):\n",
    "        \"\"\"Apply the selected transformation strategy to the query.\"\"\"\n",
    "        if not self.query_transformer or self.transformation_type == QueryTransformationType.NONE:\n",
    "            return query, 0\n",
    "\n",
    "        # Start timing for query transformation\n",
    "        start_time = time.time()\n",
    "\n",
    "        if self.transformation_type == QueryTransformationType.COOKBOOK:\n",
    "            transformed = self.query_transformer.cookbook_rewrite(query, n_variations=3)\n",
    "            transformed_query = transformed[0]  # Use the first variation\n",
    "            \n",
    "        elif self.transformation_type == QueryTransformationType.HYDE:\n",
    "            transformed_query = self.query_transformer.hyde_expansion(query)\n",
    "            \n",
    "        elif self.transformation_type == QueryTransformationType.COMPRESSION:\n",
    "            transformed_query = self.query_transformer.llm_compression(query)\n",
    "            \n",
    "        else:\n",
    "            transformed_query = query\n",
    "\n",
    "        # End timing for query transformation\n",
    "        transformation_latency = time.time() - start_time\n",
    "\n",
    "        return transformed_query, transformation_latency\n",
    "\n",
    "    def retrieve_relevant_contexts(self, query):\n",
    "        # Transform the query before retrieval\n",
    "        transformed_query, transformation_latency = self.transform_query(query)\n",
    "\n",
    "        # Retrieve the reference answer's contexts for evaluation\n",
    "        relevant_contexts = self.questions_df.iloc[self.current_idx][self.context_column]\n",
    "\n",
    "       # Standard single query processing\n",
    "        query_embedding = self.embedding_model.encode([transformed_query], convert_to_numpy=True).astype('float32')\n",
    "        distances, indices = self.index.search(query_embedding, self.k)\n",
    "        retrieved_contexts = [self.contexts[idx] for idx in indices[0] if idx < len(self.contexts)]\n",
    "\n",
    "        # Calculate metrics\n",
    "        self.questions_df.loc[self.current_idx, 'query'] = transformed_query\n",
    "        transformed_query_token = self.calculate_token_count(transformed_query)\n",
    "        self.questions_df.loc[self.current_idx, 'token_query'] = transformed_query_token\n",
    "        context_text_token = \"\\n\\n\".join(retrieved_contexts)\n",
    "        full_prompt = f\"{self.prompt_prefix}\\n\\nContext:\\n{context_text_token}\\n\\nQuestion:\\n{transformed_query}\\n\\nAnswer:\"\n",
    "        full_prompt_token_count = self.calculate_token_count(full_prompt)\n",
    "        self.questions_df.loc[self.current_idx, 'token_query_full_prompt'] = full_prompt_token_count\n",
    "      \n",
    "        # Calculate metrics if ground truth contexts are available\n",
    "        if relevant_contexts:\n",
    "            recall_k = self.recall_at_k(retrieved_contexts, relevant_contexts, self.k)\n",
    "            mrr = self.mean_reciprocal_rank(retrieved_contexts, relevant_contexts)\n",
    "            ndcg_k = self.normalized_discounted_cumulative_gain(retrieved_contexts, relevant_contexts, self.k)\n",
    "            \n",
    "            # Store metric values in the questions_df for the current question\n",
    "            self.questions_df.loc[self.current_idx, 'Recall@k'] = recall_k\n",
    "            self.questions_df.loc[self.current_idx, 'MRR'] = mrr\n",
    "            self.questions_df.loc[self.current_idx, 'nDCG@k'] = ndcg_k\n",
    "\n",
    "        return retrieved_contexts, transformation_latency\n",
    "\n",
    "    def generate_answer(self, question, retrieved_contexts, reference_answer):\n",
    "         # Start timing for retrieval and generation\n",
    "        start_time = time.time()\n",
    "        \n",
    "        delay = self.initial_delay\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                # Prepare context\n",
    "                context_text = \"\\n\\n\".join(retrieved_contexts)\n",
    "\n",
    "                client = openai.OpenAI()\n",
    "                response = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": f\"{self.prompt_prefix}\"},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Context:\\n{context_text}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n",
    "                    }\n",
    "                ],\n",
    "                model=self.model_llm,\n",
    "                temperature=self.temperature,\n",
    "                top_p=self.top_p\n",
    "                )\n",
    "                answer = response.choices[0].message.content\n",
    "\n",
    "                # End timing for retrieval and generation\n",
    "                retrieval_generation_latency = time.time() - start_time\n",
    "\n",
    "                self.questions_df.loc[self.current_idx, 'retrieval_generation_latency'] = retrieval_generation_latency\n",
    "\n",
    "                \n",
    "                # Calculate gpt_score if reference_answer is provided\n",
    "                score = self.gpt_score(answer, reference_answer) if reference_answer else None\n",
    "                \n",
    "                return answer, score \n",
    "\n",
    "            except openai.OpenAIError as e:\n",
    "                print(f\"OpenAI API error on attempt {attempt + 1}: {e}\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2  # Exponential backoff\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                return \"NO RESPONSE\", None \n",
    "        print(\"Max retries exceeded. Returning 'NO RESPONSE'.\")\n",
    "        return \"NO RESPONSE\", None \n",
    "\n",
    "    def calculate_token_count(self, prompt):\n",
    "        \"\"\"Calculate the number of tokens in a given prompt for a specified model.\"\"\"\n",
    "        encoding = tiktoken.encoding_for_model(self.model_llm)\n",
    "        tokens = encoding.encode(prompt)\n",
    "        return len(tokens)\n",
    "\n",
    "    def gpt_score(self, generated_answer, reference_answer):\n",
    "        \"\"\"Evaluates the quality of the generated answer using gpt_score.\n",
    "        \n",
    "        Args:\n",
    "            generated_answer: The answer generated by the model.\n",
    "            reference_answer: The reference (ground truth) answer.\n",
    "            \n",
    "        Returns:\n",
    "            A score indicating the quality of the generated answer.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        {self.prompt_eval_prefix}.\n",
    "        Provide a score between 0.0 and 1.0, where 1.0 indicates perfect alignment in terms of correctness, relevance, and completeness.\n",
    "    \n",
    "        Ground Truth:\n",
    "        {reference_answer}\n",
    "        \n",
    "        Generated Answer:\n",
    "        {generated_answer}\n",
    "        \n",
    "        Score (just the number):\n",
    "        \"\"\"\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model_llm,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        score = response.choices[0].message.content.strip()\n",
    "        try:\n",
    "            return float(score)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    def process_questions(self, start_index=0, output_path='output.csv'):\n",
    "        total_questions = len(self.questions_df)\n",
    "        for idx in range(start_index, total_questions):\n",
    "            self.current_idx = idx \n",
    "\n",
    "            # Start total processing time\n",
    "            total_start_time = time.time()\n",
    "\n",
    "            # Obtain question along with context and ground-truth answer\n",
    "            question = self.questions_df.iloc[idx][self.question_column]\n",
    "            retrieved_contexts, transformation_latency = self.retrieve_relevant_contexts(question)\n",
    "            reference_answer = self.questions_df.iloc[idx].get(self.answer_truth) \n",
    "\n",
    "            self.questions_df.loc[self.current_idx, 'transformation_latency'] = transformation_latency\n",
    "\n",
    "            # Generate answer\n",
    "            answer, score = self.generate_answer(question, retrieved_contexts, reference_answer)\n",
    "    \n",
    "            # End total processing time and store it\n",
    "            total_latency = time.time() - total_start_time\n",
    "            self.questions_df.loc[idx, 'total_latency'] = total_latency\n",
    "                        \n",
    "            # Use .loc[] to avoid the SettingWithCopyWarning\n",
    "            self.questions_df.loc[idx, self.answer_column] = answer\n",
    "            self.questions_df.loc[idx, 'gpt_score'] = score\n",
    "\n",
    "            # Add tokens\n",
    "            # Insert 'total_token_size' after 'token_query_full_prompt'     \n",
    "            if 'total_token_size' not in self.questions_df.columns:\n",
    "                token_query_index = self.questions_df.columns.get_loc('token_query_full_prompt')\n",
    "                self.questions_df.insert(token_query_index + 1, 'total_token_size', 0)\n",
    "\n",
    "            token_size_full_prompt = self.questions_df.loc[idx, 'token_query_full_prompt']\n",
    "            self.questions_df.loc[idx, 'total_token_size'] = token_size_full_prompt + self.calculate_token_count(answer)\n",
    "\n",
    "            # Incorporate additional token size from the transformation queries\n",
    "            if self.transformation_type == QueryTransformationType.HYDE:\n",
    "                # Create the hyde transformation prompt\n",
    "                hyde_prompt = f\"\"\"Write a detailed hypothetical passage that would perfectly answer this query:\n",
    "        \n",
    "                Query: {self.questions_df.loc[idx, self.question_column]}\n",
    "        \n",
    "                Write in a natural, informative style. Focus on key facts and details that would be relevant \n",
    "                for retrieving similar passages.\"\"\"\n",
    "                token_transform = self.calculate_token_count(hyde_prompt)\n",
    "                token_query = self.calculate_token_count(self.questions_df.loc[idx, 'query'])\n",
    "        \n",
    "                # Calculate total token size for cookbook transformation\n",
    "                self.questions_df.loc[idx, 'total_token_size'] += token_transform + token_query\n",
    "                \n",
    "            elif self.transformation_type == QueryTransformationType.COOKBOOK:\n",
    "                # Create the cookbook transformation prompt\n",
    "                cookbook_prompt = f\"\"\"Given the search query below, generate 1 different version that:\n",
    "                1. Use different relevant synonyms and terms\n",
    "                2. Maintain the core intent but vary length and style\n",
    "                3. Include both shorter and longer versions\n",
    "                \n",
    "                Original query: {self.questions_df.loc[idx, self.question_column]}\n",
    "        \n",
    "                Return just the rewritten queries, one per line.\"\"\"\n",
    "                \n",
    "                token_transform = self.calculate_token_count(cookbook_prompt)\n",
    "                token_query = self.calculate_token_count( self.questions_df.loc[idx, 'query'])\n",
    "        \n",
    "                # Calculate total token size for cookbook transformation\n",
    "                self.questions_df.loc[idx, 'total_token_size'] += token_transform + token_query\n",
    "\n",
    "            # Save progress every 'batch_size' iterations\n",
    "            if (idx + 1) % self.batch_size == 0 or idx == total_questions - 1:\n",
    "                self.questions_df.to_csv(output_path, index=False)\n",
    "                print(f\"Progress saved at question {idx + 1}/{total_questions}.\")\n",
    "        print(\"Processing complete.\")\n",
    "\n",
    "    # Retrieval Performance Metrics\n",
    "    def recall_at_k(self, retrieved, relevant, k):\n",
    "        \"\"\"Compute Recall@k for a single query.\"\"\"\n",
    "\n",
    "        relevant = relevant if isinstance(relevant, list) else [relevant]\n",
    "        retrieved_at_k = retrieved[:k]\n",
    "        relevant_retrieved = [doc for doc in retrieved_at_k if doc in relevant]\n",
    "        return len(relevant_retrieved) / len(relevant) if relevant else 0.0\n",
    "\n",
    "    def mean_reciprocal_rank(self, retrieved, relevant):\n",
    "        \"\"\"Compute Mean Reciprocal Rank (MRR) for a single query.\"\"\"\n",
    "        for idx, doc in enumerate(retrieved):\n",
    "            if doc in relevant:\n",
    "                return 1 / (idx + 1)\n",
    "        return 0.0\n",
    "\n",
    "    def discounted_cumulative_gain(self, retrieved, relevant):\n",
    "        \"\"\"Compute Discounted Cumulative Gain (DCG) for a single query.\"\"\"\n",
    "        dcg = 0.0\n",
    "        for i, doc in enumerate(retrieved):\n",
    "            if doc in relevant:\n",
    "                dcg += 1 / np.log2(i + 2)  # DCG formula with log base 2\n",
    "        return dcg\n",
    "\n",
    "    def normalized_discounted_cumulative_gain(self, retrieved, relevant, k):\n",
    "        \"\"\"Compute nDCG@k for a single query with one relevant document.\"\"\"\n",
    "        dcg_k = self.discounted_cumulative_gain(retrieved[:k], relevant)\n",
    "        ideal_dcg_k = 1 / np.log2(2)  # iDCG when relevant doc is ideally ranked first\n",
    "        return dcg_k / ideal_dcg_k if ideal_dcg_k > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41134531-2fb6-44c4-bd2f-2449a7b74b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryTransformer:\n",
    "    def __init__(self, model):\n",
    "        \"\"\"Initialize with an LLM that implements a generate() method.\n",
    "        \n",
    "        Args:\n",
    "            model: LLM instance with generate() method returning string completion\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.model_llm = 'gpt-4o'\n",
    "        self.prompt_prefix = \"You are a helpful assistant.\"\n",
    "\n",
    "    def generate_response(self, content: str) -> str:\n",
    "        \"\"\"Helper to send a standardized request to the model.\n",
    "        \n",
    "        Args:\n",
    "            content: Main content for the 'user' role in the message.\n",
    "            \n",
    "        Returns:\n",
    "            Model-generated completion as a string.\n",
    "        \"\"\"\n",
    "        response = self.model.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.prompt_prefix},\n",
    "                {\"role\": \"user\", \"content\": content}\n",
    "            ],\n",
    "            model=self.model_llm\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "        \n",
    "\n",
    "    def cookbook_rewrite(self, query: str, n_variations: int = 3) -> List[str]:\n",
    "        \"\"\"Implements Microsoft AI Cookbook query rewriting strategy.\n",
    "        \n",
    "        Args:\n",
    "            query: Original user query\n",
    "            n_variations: Number of rewrites to generate\n",
    "            \n",
    "        Returns:\n",
    "            List of rewritten queries\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Given the search query below, generate {n_variations} different versions that:\n",
    "        1. Use different relevant synonyms and terms\n",
    "        2. Maintain the core intent but vary length and style\n",
    "        3. Include both shorter and longer versions\n",
    "        \n",
    "        Original query: {query}\n",
    "        \n",
    "        Return just the rewritten queries, one per line.\"\"\"\n",
    "\n",
    "        response = self.generate_response(prompt)\n",
    "        variations = [q.strip() for q in response.split('\\n') if q.strip()]\n",
    "        return variations[:n_variations]\n",
    "\n",
    "    def hyde_expansion(self, query: str) -> str:\n",
    "        \"\"\"Implements HyDE (Hypothetical Document Embedding) expansion.\n",
    "        \n",
    "        Args:\n",
    "            query: Original user query\n",
    "            \n",
    "        Returns:\n",
    "            Expanded query with hypothetical answer context\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Write a detailed hypothetical passage that would perfectly answer this query:\n",
    "        \n",
    "        Query: {query}\n",
    "        \n",
    "        Write in a natural, informative style. Focus on key facts and details that would be relevant \n",
    "        for retrieving similar passages.\"\"\"\n",
    "\n",
    "        hypothetical_doc = self.generate_response(prompt)\n",
    "        \n",
    "        # Combine original query with hypothetical document\n",
    "        expanded_query = f\"{query}\\n\\nRelevant context: {hypothetical_doc}\"\n",
    "        return expanded_query\n",
    "\n",
    "\n",
    "    def llm_compression(self, query, comp_rate=0.5):\n",
    "        \"\"\"Implements LLM-based query compression using LLMLingua.\n",
    "        \n",
    "        Args:\n",
    "            query: Original user query\n",
    "            comp_rate: Compression rate\n",
    "            \n",
    "        Returns:\n",
    "            Compressed query maintaining key intent\n",
    "        \"\"\"\n",
    "\n",
    "        # Load compressor\n",
    "        compressor = PromptCompressor(\n",
    "              model_name=\"microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank\",\n",
    "              use_llmlingua2=True, # Use llmlingua-2\n",
    "        )\n",
    "\n",
    "        # Compress prompt\n",
    "        compressed_output = compressor.compress_prompt(\n",
    "            query,\n",
    "            rate=comp_rate\n",
    "        )\n",
    "\n",
    "        return compressed_output[\"compressed_prompt\"]\n",
    "        \n",
    "    def transform_query(self, \n",
    "                       query: str,\n",
    "                       strategies: List[str],\n",
    "                       **kwargs) -> dict:\n",
    "        \"\"\"Apply multiple transformation strategies to a query.\n",
    "        \n",
    "        Args:\n",
    "            query: Original user query\n",
    "            strategies: List of strategies to apply ('rewrite', 'hyde', 'compress', 'chunk')\n",
    "            **kwargs: Strategy-specific parameters\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping strategy names to transformed queries\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for strategy in strategies:\n",
    "            if strategy == 'rewrite':\n",
    "                n = kwargs.get('n_variations', 3)\n",
    "                results['rewrite'] = self.cookbook_rewrite(query, n)\n",
    "            elif strategy == 'hyde':\n",
    "                results['hyde'] = self.hyde_expansion(query)\n",
    "            elif strategy == 'compress':\n",
    "                max_tokens = kwargs.get('max_tokens', 50)\n",
    "                results['compress'] = self.llm_compression(query, max_tokens)\n",
    "                \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c680222-c508-4830-8f95-ab6fd4f3b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_answers(sector, df, transformation_type = QueryTransformationType.NONE, output_suffix: str = \"baseline\"):\n",
    "    \"\"\"\n",
    "    Populate baseline answers using specified query transformation strategy.\n",
    "    \n",
    "    Args:\n",
    "        sector: Sector identifier\n",
    "        df: Input DataFrame with questions\n",
    "        transformation_type: Query transformation strategy to use\n",
    "        output_suffix: Suffix for output filename\n",
    "    \"\"\"\n",
    "    # Select sector configuration\n",
    "    sector_config = SECTORS[sector]\n",
    "    \n",
    "    # Extract hyperparameters from sector config\n",
    "    hyperparameters = {\n",
    "        'top_p': sector_config['hyperparameters']['top_p'],\n",
    "        'temperature': sector_config['hyperparameters']['temperature'],\n",
    "        'k': sector_config['hyperparameters']['k'],\n",
    "        'batch_size': sector_config['hyperparameters']['batch_size'],\n",
    "        'max_retries': sector_config['hyperparameters']['max_retries'],\n",
    "        'initial_delay': sector_config['hyperparameters']['initial_delay']\n",
    "    }\n",
    "    \n",
    "    # Initialize RAGSystem with transformation strategy\n",
    "    rag_system = RAGSystem(\n",
    "        sector_config=sector_config,\n",
    "        hyperparameters=hyperparameters,\n",
    "        questions_df=df,\n",
    "        faiss_index_path=None,\n",
    "        transformation_type=transformation_type,\n",
    "        model_name='gpt-4o'\n",
    "    )\n",
    "    \n",
    "    # Create output filename based on transformation type\n",
    "    transform_name = transformation_type.value if isinstance(transformation_type, QueryTransformationType) else transformation_type\n",
    "    if output_suffix == \"baseline\": \n",
    "        output_suffix = transform_name\n",
    "    \n",
    "    output_path = f'data/{sector}/processed/2_{sector}_{output_suffix}.csv'\n",
    "    \n",
    "    # Process questions and save to output file\n",
    "    rag_system.process_questions(start_index=0, output_path=output_path)\n",
    "    \n",
    "    print(f'Output saved in: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766f93b-826c-48a6-960e-b9f5aec5c7de",
   "metadata": {},
   "source": [
    "## Populate answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21303955-a1c1-46a9-b931-e268e277b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sampling(sector, sample_size=10, random_state=42):\n",
    "    sector_config = SECTORS[sector]\n",
    "\n",
    "    # Read the file\n",
    "    df = pd.read_csv(sector_config['dataset_test'])\n",
    "\n",
    "    # Define required columns\n",
    "    required_columns = [\n",
    "        sector_config['context_column'],\n",
    "        'question',\n",
    "        sector_config['answer_truth'],\n",
    "        'topic_lda'\n",
    "    ]\n",
    "    \n",
    "    # Conditionally add `question_category` if available\n",
    "    question_category = sector_config.get('question_category', None)\n",
    "    if question_category and question_category in df.columns:\n",
    "        required_columns.append(question_category)\n",
    "        has_question_category = True\n",
    "    else:\n",
    "        has_question_category = False\n",
    "\n",
    "    # Ensure required columns exist in the DataFrame\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Required column '{col}' not found in the DataFrame.\")\n",
    "\n",
    "    # Convert 'answer_truth' column from list to string (select the first answer if it's a list)\n",
    "    df[sector_config['answer_truth']] = df[sector_config['answer_truth']].apply(\n",
    "        lambda x: x[0] if isinstance(x, list) else x\n",
    "    )\n",
    "    \n",
    "    # Drop duplicates and keep only required columns\n",
    "    df = df[required_columns].drop_duplicates()\n",
    "\n",
    "    # Perform stratified sampling\n",
    "    if has_question_category:\n",
    "        # Stratify based on both `topic_lda` and `question_category`\n",
    "        sampled_df = df.groupby(['topic_lda', question_category], group_keys=False).apply(\n",
    "            lambda x: x.sample(n=min(sample_size, len(x)), random_state=random_state)\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        # Stratify based on `topic_lda` only\n",
    "        sampled_df = df.groupby('topic_lda', group_keys=False).apply(\n",
    "            lambda x: x.sample(n=min(sample_size, len(x)), random_state=random_state)\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4cdaa-d6cc-4dcb-937f-f9f18c15baea",
   "metadata": {},
   "source": [
    "### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb8e552-4408-4bdb-95bd-4315668fd324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emir\\AppData\\Local\\Temp\\ipykernel_12652\\3075347949.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(['topic_lda', question_category], group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Perform stratified sampling from testing dataset\n",
    "edu_sampled_df = stratified_sampling('education', sample_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c517c46f-e505-4868-8d61-8a4e44afacdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95eb12a3-e28e-4e7f-9fa7-4fe7c3c47832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_class\n",
       "DESC    160\n",
       "ENTY    160\n",
       "HUM     160\n",
       "LOC     160\n",
       "NUM     160\n",
       "ABBR    129\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_sampled_df['question_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7267e34c-e930-40dd-92c6-cd0fb92a3282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_lda\n",
       "1    240\n",
       "2    240\n",
       "0    225\n",
       "3    224\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_sampled_df['topic_lda'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6865c79d-2871-4ebf-a6dc-7e5077fa1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_sampled_df.to_csv('data/education/processed/1_education_noanswer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f6284-d79f-4eb3-ad9f-942837a3c418",
   "metadata": {},
   "source": [
    "#### Few-shot prompting (education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7609cc50-206d-4ad7-a44c-4354ad5299a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>topic_lda</th>\n",
       "      <th>question_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The majority of Greek Cypriots identify as Gre...</td>\n",
       "      <td>What religion do most Turkish Cypriots identif...</td>\n",
       "      <td>Sunni Islam</td>\n",
       "      <td>0</td>\n",
       "      <td>ENTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guinea-Bissau's GDP per capita is one of the l...</td>\n",
       "      <td>What are Guinea-Bissau's major exports?</td>\n",
       "      <td>fish, cashew nuts and ground nuts</td>\n",
       "      <td>2</td>\n",
       "      <td>DESC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autodidacticism (also autodidactism) is a cont...</td>\n",
       "      <td>Which famous inventor was a Autodidact?</td>\n",
       "      <td>Thomas Alva Edison</td>\n",
       "      <td>1</td>\n",
       "      <td>HUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lacey Act of 1900 was the first federal la...</td>\n",
       "      <td>What did the first federal wildlife commerce l...</td>\n",
       "      <td>interstate commerce of animals killed in viola...</td>\n",
       "      <td>2</td>\n",
       "      <td>ENTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Forbes Kerry was born on December 11, 194...</td>\n",
       "      <td>What was Kerry's mother's religion?</td>\n",
       "      <td>Episcopalian</td>\n",
       "      <td>3</td>\n",
       "      <td>ENTY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  The majority of Greek Cypriots identify as Gre...   \n",
       "1  Guinea-Bissau's GDP per capita is one of the l...   \n",
       "2  Autodidacticism (also autodidactism) is a cont...   \n",
       "3  The Lacey Act of 1900 was the first federal la...   \n",
       "4  John Forbes Kerry was born on December 11, 194...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What religion do most Turkish Cypriots identif...   \n",
       "1            What are Guinea-Bissau's major exports?   \n",
       "2            Which famous inventor was a Autodidact?   \n",
       "3  What did the first federal wildlife commerce l...   \n",
       "4                What was Kerry's mother's religion?   \n",
       "\n",
       "                                             answers  topic_lda question_class  \n",
       "0                                        Sunni Islam          0           ENTY  \n",
       "1                  fish, cashew nuts and ground nuts          2           DESC  \n",
       "2                                 Thomas Alva Edison          1            HUM  \n",
       "3  interstate commerce of animals killed in viola...          2           ENTY  \n",
       "4                                       Episcopalian          3           ENTY  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract unique contexts from the testing dataset (edu_sampled_df)\n",
    "testing_contexts = edu_sampled_df['context'].unique()\n",
    "\n",
    "# Read the entire dataset\n",
    "df = pd.read_csv(SECTORS['education']['dataset_test'])\n",
    "\n",
    "# Filter rows where the context is not in the testing contexts\n",
    "filtered_df = df[~df['context'].isin(testing_contexts)]\n",
    "\n",
    "# Display the filtered DataFrame containing only questions with unique contexts not in the testing dataset\n",
    "filtered_df.to_csv('data/education/processed/1_education_few-shot.csv', index=False)\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7217fa7b-4ce7-4aea-8928-4cce21ededba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the name of Shen Fu's memoir?\n",
    "# Six Chapters of a Floating Life\n",
    "\n",
    "# What became more common during the Baroque era?\n",
    "# vocal forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd77c3b6-63e8-409a-9686-5d5e797593a4",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dab3fdf-0e64-49c7-96af-d0ec9b0f93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the education testing dataset\n",
    "edu_sampled_df = pd.read_csv('data/education/processed/1_education_noanswer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23b36312-0f37-4637-b598-364bebd2cfdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from ..\\models\\embeddings\\squad_faiss_index_new.idx...\n",
      "Progress saved at question 5/929.\n",
      "Progress saved at question 10/929.\n",
      "Progress saved at question 15/929.\n",
      "Progress saved at question 20/929.\n",
      "Progress saved at question 25/929.\n",
      "Progress saved at question 30/929.\n",
      "Progress saved at question 35/929.\n",
      "Progress saved at question 40/929.\n",
      "Progress saved at question 45/929.\n",
      "Progress saved at question 50/929.\n",
      "Progress saved at question 55/929.\n",
      "Progress saved at question 60/929.\n",
      "Progress saved at question 65/929.\n",
      "Progress saved at question 70/929.\n",
      "Progress saved at question 75/929.\n",
      "Progress saved at question 80/929.\n",
      "Progress saved at question 85/929.\n",
      "Progress saved at question 90/929.\n",
      "Progress saved at question 95/929.\n",
      "Progress saved at question 100/929.\n",
      "Progress saved at question 105/929.\n",
      "Progress saved at question 110/929.\n",
      "Progress saved at question 115/929.\n",
      "Progress saved at question 120/929.\n",
      "Progress saved at question 125/929.\n",
      "Progress saved at question 130/929.\n",
      "Progress saved at question 135/929.\n",
      "Progress saved at question 140/929.\n",
      "Progress saved at question 145/929.\n",
      "Progress saved at question 150/929.\n",
      "Progress saved at question 155/929.\n",
      "Progress saved at question 160/929.\n",
      "Progress saved at question 165/929.\n",
      "Progress saved at question 170/929.\n",
      "Progress saved at question 175/929.\n",
      "Progress saved at question 180/929.\n",
      "Progress saved at question 185/929.\n",
      "Progress saved at question 190/929.\n",
      "Progress saved at question 195/929.\n",
      "Progress saved at question 200/929.\n",
      "Progress saved at question 205/929.\n",
      "Progress saved at question 210/929.\n",
      "Progress saved at question 215/929.\n",
      "Progress saved at question 220/929.\n",
      "Progress saved at question 225/929.\n",
      "Progress saved at question 230/929.\n",
      "Progress saved at question 235/929.\n",
      "Progress saved at question 240/929.\n",
      "Progress saved at question 245/929.\n",
      "Progress saved at question 250/929.\n",
      "Progress saved at question 255/929.\n",
      "Progress saved at question 260/929.\n",
      "Progress saved at question 265/929.\n",
      "Progress saved at question 270/929.\n",
      "Progress saved at question 275/929.\n",
      "Progress saved at question 280/929.\n",
      "Progress saved at question 285/929.\n",
      "Progress saved at question 290/929.\n",
      "Progress saved at question 295/929.\n",
      "Progress saved at question 300/929.\n",
      "Progress saved at question 305/929.\n",
      "Progress saved at question 310/929.\n",
      "Progress saved at question 315/929.\n",
      "Progress saved at question 320/929.\n",
      "Progress saved at question 325/929.\n",
      "Progress saved at question 330/929.\n",
      "Progress saved at question 335/929.\n",
      "Progress saved at question 340/929.\n",
      "Progress saved at question 345/929.\n",
      "Progress saved at question 350/929.\n",
      "Progress saved at question 355/929.\n",
      "Progress saved at question 360/929.\n",
      "Progress saved at question 365/929.\n",
      "Progress saved at question 370/929.\n",
      "Progress saved at question 375/929.\n",
      "Progress saved at question 380/929.\n",
      "Progress saved at question 385/929.\n",
      "Progress saved at question 390/929.\n",
      "Progress saved at question 395/929.\n",
      "Progress saved at question 400/929.\n",
      "Progress saved at question 405/929.\n",
      "Progress saved at question 410/929.\n",
      "Progress saved at question 415/929.\n",
      "Progress saved at question 420/929.\n",
      "Progress saved at question 425/929.\n",
      "Progress saved at question 430/929.\n",
      "Progress saved at question 435/929.\n",
      "Progress saved at question 440/929.\n",
      "Progress saved at question 445/929.\n",
      "Progress saved at question 450/929.\n",
      "Progress saved at question 455/929.\n",
      "Progress saved at question 460/929.\n",
      "Progress saved at question 465/929.\n",
      "Progress saved at question 470/929.\n",
      "Progress saved at question 475/929.\n",
      "Progress saved at question 480/929.\n",
      "Progress saved at question 485/929.\n",
      "Progress saved at question 490/929.\n",
      "Progress saved at question 495/929.\n",
      "Progress saved at question 500/929.\n",
      "Progress saved at question 505/929.\n",
      "Progress saved at question 510/929.\n",
      "Progress saved at question 515/929.\n",
      "Progress saved at question 520/929.\n",
      "Progress saved at question 525/929.\n",
      "Progress saved at question 530/929.\n",
      "Progress saved at question 535/929.\n",
      "Progress saved at question 540/929.\n",
      "Progress saved at question 545/929.\n",
      "Progress saved at question 550/929.\n",
      "Progress saved at question 555/929.\n",
      "Progress saved at question 560/929.\n",
      "Progress saved at question 565/929.\n",
      "Progress saved at question 570/929.\n",
      "Progress saved at question 575/929.\n",
      "Progress saved at question 580/929.\n",
      "Progress saved at question 585/929.\n",
      "Progress saved at question 590/929.\n",
      "Progress saved at question 595/929.\n",
      "Progress saved at question 600/929.\n",
      "Progress saved at question 605/929.\n",
      "Progress saved at question 610/929.\n",
      "Progress saved at question 615/929.\n",
      "Progress saved at question 620/929.\n",
      "Progress saved at question 625/929.\n",
      "Progress saved at question 630/929.\n",
      "Progress saved at question 635/929.\n",
      "Progress saved at question 640/929.\n",
      "Progress saved at question 645/929.\n",
      "Progress saved at question 650/929.\n",
      "Progress saved at question 655/929.\n",
      "Progress saved at question 660/929.\n",
      "Progress saved at question 665/929.\n",
      "Progress saved at question 670/929.\n",
      "Progress saved at question 675/929.\n",
      "Progress saved at question 680/929.\n",
      "Progress saved at question 685/929.\n",
      "Progress saved at question 690/929.\n",
      "Progress saved at question 695/929.\n",
      "Progress saved at question 700/929.\n",
      "Progress saved at question 705/929.\n",
      "Progress saved at question 710/929.\n",
      "Progress saved at question 715/929.\n",
      "Progress saved at question 720/929.\n",
      "Progress saved at question 725/929.\n",
      "Progress saved at question 730/929.\n",
      "Progress saved at question 735/929.\n",
      "Progress saved at question 740/929.\n",
      "Progress saved at question 745/929.\n",
      "Progress saved at question 750/929.\n",
      "Progress saved at question 755/929.\n",
      "Progress saved at question 760/929.\n",
      "Progress saved at question 765/929.\n",
      "Progress saved at question 770/929.\n",
      "Progress saved at question 775/929.\n",
      "Progress saved at question 780/929.\n",
      "Progress saved at question 785/929.\n",
      "Progress saved at question 790/929.\n",
      "Progress saved at question 795/929.\n",
      "Progress saved at question 800/929.\n",
      "Progress saved at question 805/929.\n",
      "Progress saved at question 810/929.\n",
      "Progress saved at question 815/929.\n",
      "Progress saved at question 820/929.\n",
      "Progress saved at question 825/929.\n",
      "Progress saved at question 830/929.\n",
      "Progress saved at question 835/929.\n",
      "Progress saved at question 840/929.\n",
      "Progress saved at question 845/929.\n",
      "Progress saved at question 850/929.\n",
      "Progress saved at question 855/929.\n",
      "Progress saved at question 860/929.\n",
      "Progress saved at question 865/929.\n",
      "Progress saved at question 870/929.\n",
      "Progress saved at question 875/929.\n",
      "Progress saved at question 880/929.\n",
      "Progress saved at question 885/929.\n",
      "Progress saved at question 890/929.\n",
      "Progress saved at question 895/929.\n",
      "Progress saved at question 900/929.\n",
      "Progress saved at question 905/929.\n",
      "Progress saved at question 910/929.\n",
      "Progress saved at question 915/929.\n",
      "Progress saved at question 920/929.\n",
      "Progress saved at question 925/929.\n",
      "Progress saved at question 929/929.\n",
      "Processing complete.\n",
      "Output saved in: data/education/processed/2_education_baseline.csv\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "populate_answers(\"education\", edu_sampled_df, QueryTransformationType.BASELINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a3253-bacb-4c80-a47c-82f765ac085c",
   "metadata": {},
   "source": [
    "#### Query transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18836b0a-55d8-4095-9e57-c7461a49a514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from ..\\models\\embeddings\\squad_faiss_index_new.idx...\n",
      "Progress saved at question 5/929.\n",
      "Progress saved at question 10/929.\n",
      "Progress saved at question 15/929.\n",
      "Progress saved at question 20/929.\n",
      "Progress saved at question 25/929.\n",
      "Progress saved at question 30/929.\n",
      "Progress saved at question 35/929.\n",
      "Progress saved at question 40/929.\n",
      "Progress saved at question 45/929.\n",
      "Progress saved at question 50/929.\n",
      "Progress saved at question 55/929.\n",
      "Progress saved at question 60/929.\n",
      "Progress saved at question 65/929.\n",
      "Progress saved at question 70/929.\n",
      "Progress saved at question 75/929.\n",
      "Progress saved at question 80/929.\n",
      "Progress saved at question 85/929.\n",
      "Progress saved at question 90/929.\n",
      "Progress saved at question 95/929.\n",
      "Progress saved at question 100/929.\n",
      "Progress saved at question 105/929.\n",
      "Progress saved at question 110/929.\n",
      "Progress saved at question 115/929.\n",
      "Progress saved at question 120/929.\n",
      "Progress saved at question 125/929.\n",
      "Progress saved at question 130/929.\n",
      "Progress saved at question 135/929.\n",
      "Progress saved at question 140/929.\n",
      "Progress saved at question 145/929.\n",
      "Progress saved at question 150/929.\n",
      "Progress saved at question 155/929.\n",
      "Progress saved at question 160/929.\n",
      "Progress saved at question 165/929.\n",
      "Progress saved at question 170/929.\n",
      "Progress saved at question 175/929.\n",
      "Progress saved at question 180/929.\n",
      "Progress saved at question 185/929.\n",
      "Progress saved at question 190/929.\n",
      "Progress saved at question 195/929.\n",
      "Progress saved at question 200/929.\n",
      "Progress saved at question 205/929.\n",
      "Progress saved at question 210/929.\n",
      "Progress saved at question 215/929.\n",
      "Progress saved at question 220/929.\n",
      "Progress saved at question 225/929.\n",
      "Progress saved at question 230/929.\n",
      "Progress saved at question 235/929.\n",
      "Progress saved at question 240/929.\n",
      "Progress saved at question 245/929.\n",
      "Progress saved at question 250/929.\n",
      "Progress saved at question 255/929.\n",
      "Progress saved at question 260/929.\n",
      "Progress saved at question 265/929.\n",
      "Progress saved at question 270/929.\n",
      "Progress saved at question 275/929.\n",
      "Progress saved at question 280/929.\n",
      "Progress saved at question 285/929.\n",
      "Progress saved at question 290/929.\n",
      "Progress saved at question 295/929.\n",
      "Progress saved at question 300/929.\n",
      "Progress saved at question 305/929.\n",
      "Progress saved at question 310/929.\n",
      "Progress saved at question 315/929.\n",
      "Progress saved at question 320/929.\n",
      "Progress saved at question 325/929.\n",
      "Progress saved at question 330/929.\n",
      "Progress saved at question 335/929.\n",
      "Progress saved at question 340/929.\n",
      "Progress saved at question 345/929.\n",
      "Progress saved at question 350/929.\n",
      "Progress saved at question 355/929.\n",
      "Progress saved at question 360/929.\n",
      "Progress saved at question 365/929.\n",
      "Progress saved at question 370/929.\n",
      "Progress saved at question 375/929.\n",
      "Progress saved at question 380/929.\n",
      "Progress saved at question 385/929.\n",
      "Progress saved at question 390/929.\n",
      "Progress saved at question 395/929.\n",
      "Progress saved at question 400/929.\n",
      "Progress saved at question 405/929.\n",
      "Progress saved at question 410/929.\n",
      "Progress saved at question 415/929.\n",
      "Progress saved at question 420/929.\n",
      "Progress saved at question 425/929.\n",
      "Progress saved at question 430/929.\n",
      "Progress saved at question 435/929.\n",
      "Progress saved at question 440/929.\n",
      "Progress saved at question 445/929.\n",
      "Progress saved at question 450/929.\n",
      "Progress saved at question 455/929.\n",
      "Progress saved at question 460/929.\n",
      "Progress saved at question 465/929.\n",
      "Progress saved at question 470/929.\n",
      "Progress saved at question 475/929.\n",
      "Progress saved at question 480/929.\n",
      "Progress saved at question 485/929.\n",
      "Progress saved at question 490/929.\n",
      "Progress saved at question 495/929.\n",
      "Progress saved at question 500/929.\n",
      "Progress saved at question 505/929.\n",
      "Progress saved at question 510/929.\n",
      "Progress saved at question 515/929.\n",
      "Progress saved at question 520/929.\n",
      "Progress saved at question 525/929.\n",
      "Progress saved at question 530/929.\n",
      "Progress saved at question 535/929.\n",
      "Progress saved at question 540/929.\n",
      "Progress saved at question 545/929.\n",
      "Progress saved at question 550/929.\n",
      "Progress saved at question 555/929.\n",
      "Progress saved at question 560/929.\n",
      "Progress saved at question 565/929.\n",
      "Progress saved at question 570/929.\n",
      "Progress saved at question 575/929.\n",
      "Progress saved at question 580/929.\n",
      "Progress saved at question 585/929.\n",
      "Progress saved at question 590/929.\n",
      "Progress saved at question 595/929.\n",
      "Progress saved at question 600/929.\n",
      "Progress saved at question 605/929.\n",
      "Progress saved at question 610/929.\n",
      "Progress saved at question 615/929.\n",
      "Progress saved at question 620/929.\n",
      "Progress saved at question 625/929.\n",
      "Progress saved at question 630/929.\n",
      "Progress saved at question 635/929.\n",
      "Progress saved at question 640/929.\n",
      "Progress saved at question 645/929.\n",
      "Progress saved at question 650/929.\n",
      "Progress saved at question 655/929.\n",
      "Progress saved at question 660/929.\n",
      "Progress saved at question 665/929.\n",
      "Progress saved at question 670/929.\n",
      "Progress saved at question 675/929.\n",
      "Progress saved at question 680/929.\n",
      "Progress saved at question 685/929.\n",
      "Progress saved at question 690/929.\n",
      "Progress saved at question 695/929.\n",
      "Progress saved at question 700/929.\n",
      "Progress saved at question 705/929.\n",
      "Progress saved at question 710/929.\n",
      "Progress saved at question 715/929.\n",
      "Progress saved at question 720/929.\n",
      "Progress saved at question 725/929.\n",
      "Progress saved at question 730/929.\n",
      "Progress saved at question 735/929.\n",
      "Progress saved at question 740/929.\n",
      "Progress saved at question 745/929.\n",
      "Progress saved at question 750/929.\n",
      "Progress saved at question 755/929.\n",
      "Progress saved at question 760/929.\n",
      "Progress saved at question 765/929.\n",
      "Progress saved at question 770/929.\n",
      "Progress saved at question 775/929.\n",
      "Progress saved at question 780/929.\n",
      "Progress saved at question 785/929.\n",
      "Progress saved at question 790/929.\n",
      "Progress saved at question 795/929.\n",
      "Progress saved at question 800/929.\n",
      "Progress saved at question 805/929.\n",
      "Progress saved at question 810/929.\n",
      "Progress saved at question 815/929.\n",
      "Progress saved at question 820/929.\n",
      "Progress saved at question 825/929.\n",
      "Progress saved at question 830/929.\n",
      "Progress saved at question 835/929.\n",
      "Progress saved at question 840/929.\n",
      "Progress saved at question 845/929.\n",
      "Progress saved at question 850/929.\n",
      "Progress saved at question 855/929.\n",
      "Progress saved at question 860/929.\n",
      "Progress saved at question 865/929.\n",
      "Progress saved at question 870/929.\n",
      "Progress saved at question 875/929.\n",
      "Progress saved at question 880/929.\n",
      "Progress saved at question 885/929.\n",
      "Progress saved at question 890/929.\n",
      "Progress saved at question 895/929.\n",
      "Progress saved at question 900/929.\n",
      "Progress saved at question 905/929.\n",
      "Progress saved at question 910/929.\n",
      "Progress saved at question 915/929.\n",
      "Progress saved at question 920/929.\n",
      "Progress saved at question 925/929.\n",
      "Progress saved at question 929/929.\n",
      "Processing complete.\n",
      "Output saved in: data/education/processed/2_education_cookbook.csv\n"
     ]
    }
   ],
   "source": [
    "# Using cookbook rewriting\n",
    "populate_answers(\"education\", edu_sampled_df, QueryTransformationType.COOKBOOK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7d0f2c4-51b0-4bec-9ae7-1550f5572314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from ..\\models\\embeddings\\squad_faiss_index_new.idx...\n",
      "Progress saved at question 5/929.\n",
      "Progress saved at question 10/929.\n",
      "Progress saved at question 15/929.\n",
      "Progress saved at question 20/929.\n",
      "Progress saved at question 25/929.\n",
      "Progress saved at question 30/929.\n",
      "Progress saved at question 35/929.\n",
      "Progress saved at question 40/929.\n",
      "Progress saved at question 45/929.\n",
      "Progress saved at question 50/929.\n",
      "Progress saved at question 55/929.\n",
      "Progress saved at question 60/929.\n",
      "Progress saved at question 65/929.\n",
      "Progress saved at question 70/929.\n",
      "Progress saved at question 75/929.\n",
      "Progress saved at question 80/929.\n",
      "Progress saved at question 85/929.\n",
      "Progress saved at question 90/929.\n",
      "Progress saved at question 95/929.\n",
      "Progress saved at question 100/929.\n",
      "Progress saved at question 105/929.\n",
      "Progress saved at question 110/929.\n",
      "Progress saved at question 115/929.\n",
      "Progress saved at question 120/929.\n",
      "Progress saved at question 125/929.\n",
      "Progress saved at question 130/929.\n",
      "Progress saved at question 135/929.\n",
      "Progress saved at question 140/929.\n",
      "Progress saved at question 145/929.\n",
      "Progress saved at question 150/929.\n",
      "Progress saved at question 155/929.\n",
      "Progress saved at question 160/929.\n",
      "Progress saved at question 165/929.\n",
      "Progress saved at question 170/929.\n",
      "Progress saved at question 175/929.\n",
      "Progress saved at question 180/929.\n",
      "Progress saved at question 185/929.\n",
      "Progress saved at question 190/929.\n",
      "Progress saved at question 195/929.\n",
      "Progress saved at question 200/929.\n",
      "Progress saved at question 205/929.\n",
      "Progress saved at question 210/929.\n",
      "Progress saved at question 215/929.\n",
      "Progress saved at question 220/929.\n",
      "Progress saved at question 225/929.\n",
      "Progress saved at question 230/929.\n",
      "Progress saved at question 235/929.\n",
      "Progress saved at question 240/929.\n",
      "Progress saved at question 245/929.\n",
      "Progress saved at question 250/929.\n",
      "Progress saved at question 255/929.\n",
      "Progress saved at question 260/929.\n",
      "Progress saved at question 265/929.\n",
      "Progress saved at question 270/929.\n",
      "Progress saved at question 275/929.\n",
      "Progress saved at question 280/929.\n",
      "Progress saved at question 285/929.\n",
      "Progress saved at question 290/929.\n",
      "Progress saved at question 295/929.\n",
      "Progress saved at question 300/929.\n",
      "Progress saved at question 305/929.\n",
      "Progress saved at question 310/929.\n",
      "Progress saved at question 315/929.\n",
      "Progress saved at question 320/929.\n",
      "Progress saved at question 325/929.\n",
      "Progress saved at question 330/929.\n",
      "Progress saved at question 335/929.\n",
      "Progress saved at question 340/929.\n",
      "Progress saved at question 345/929.\n",
      "Progress saved at question 350/929.\n",
      "Progress saved at question 355/929.\n",
      "Progress saved at question 360/929.\n",
      "Progress saved at question 365/929.\n",
      "Progress saved at question 370/929.\n",
      "Progress saved at question 375/929.\n",
      "Progress saved at question 380/929.\n",
      "Progress saved at question 385/929.\n",
      "Progress saved at question 390/929.\n",
      "Progress saved at question 395/929.\n",
      "Progress saved at question 400/929.\n",
      "Progress saved at question 405/929.\n",
      "Progress saved at question 410/929.\n",
      "Progress saved at question 415/929.\n",
      "Progress saved at question 420/929.\n",
      "Progress saved at question 425/929.\n",
      "Progress saved at question 430/929.\n",
      "Progress saved at question 435/929.\n",
      "Progress saved at question 440/929.\n",
      "Progress saved at question 445/929.\n",
      "Progress saved at question 450/929.\n",
      "Progress saved at question 455/929.\n",
      "Progress saved at question 460/929.\n",
      "Progress saved at question 465/929.\n",
      "Progress saved at question 470/929.\n",
      "Progress saved at question 475/929.\n",
      "Progress saved at question 480/929.\n",
      "Progress saved at question 485/929.\n",
      "Progress saved at question 490/929.\n",
      "Progress saved at question 495/929.\n",
      "Progress saved at question 500/929.\n",
      "Progress saved at question 505/929.\n",
      "Progress saved at question 510/929.\n",
      "Progress saved at question 515/929.\n",
      "Progress saved at question 520/929.\n",
      "Progress saved at question 525/929.\n",
      "Progress saved at question 530/929.\n",
      "Progress saved at question 535/929.\n",
      "Progress saved at question 540/929.\n",
      "Progress saved at question 545/929.\n",
      "Progress saved at question 550/929.\n",
      "Progress saved at question 555/929.\n",
      "Progress saved at question 560/929.\n",
      "Progress saved at question 565/929.\n",
      "Progress saved at question 570/929.\n",
      "Progress saved at question 575/929.\n",
      "Progress saved at question 580/929.\n",
      "Progress saved at question 585/929.\n",
      "Progress saved at question 590/929.\n",
      "Progress saved at question 595/929.\n",
      "Progress saved at question 600/929.\n",
      "Progress saved at question 605/929.\n",
      "Progress saved at question 610/929.\n",
      "Progress saved at question 615/929.\n",
      "Progress saved at question 620/929.\n",
      "Progress saved at question 625/929.\n",
      "Progress saved at question 630/929.\n",
      "Progress saved at question 635/929.\n",
      "Progress saved at question 640/929.\n",
      "Progress saved at question 645/929.\n",
      "Progress saved at question 650/929.\n",
      "Progress saved at question 655/929.\n",
      "Progress saved at question 660/929.\n",
      "Progress saved at question 665/929.\n",
      "Progress saved at question 670/929.\n",
      "Progress saved at question 675/929.\n",
      "Progress saved at question 680/929.\n",
      "Progress saved at question 685/929.\n",
      "Progress saved at question 690/929.\n",
      "Progress saved at question 695/929.\n",
      "Progress saved at question 700/929.\n",
      "Progress saved at question 705/929.\n",
      "Progress saved at question 710/929.\n",
      "Progress saved at question 715/929.\n",
      "Progress saved at question 720/929.\n",
      "Progress saved at question 725/929.\n",
      "Progress saved at question 730/929.\n",
      "Progress saved at question 735/929.\n",
      "Progress saved at question 740/929.\n",
      "Progress saved at question 745/929.\n",
      "Progress saved at question 750/929.\n",
      "Progress saved at question 755/929.\n",
      "Progress saved at question 760/929.\n",
      "Progress saved at question 765/929.\n",
      "Progress saved at question 770/929.\n",
      "Progress saved at question 775/929.\n",
      "Progress saved at question 780/929.\n",
      "Progress saved at question 785/929.\n",
      "Progress saved at question 790/929.\n",
      "Progress saved at question 795/929.\n",
      "Progress saved at question 800/929.\n",
      "Progress saved at question 805/929.\n",
      "Progress saved at question 810/929.\n",
      "Progress saved at question 815/929.\n",
      "Progress saved at question 820/929.\n",
      "Progress saved at question 825/929.\n",
      "Progress saved at question 830/929.\n",
      "Progress saved at question 835/929.\n",
      "Progress saved at question 840/929.\n",
      "Progress saved at question 845/929.\n",
      "Progress saved at question 850/929.\n",
      "Progress saved at question 855/929.\n",
      "Progress saved at question 860/929.\n",
      "Progress saved at question 865/929.\n",
      "Progress saved at question 870/929.\n",
      "Progress saved at question 875/929.\n",
      "Progress saved at question 880/929.\n",
      "Progress saved at question 885/929.\n",
      "Progress saved at question 890/929.\n",
      "Progress saved at question 895/929.\n",
      "Progress saved at question 900/929.\n",
      "Progress saved at question 905/929.\n",
      "Progress saved at question 910/929.\n",
      "Progress saved at question 915/929.\n",
      "Progress saved at question 920/929.\n",
      "Progress saved at question 925/929.\n",
      "Progress saved at question 929/929.\n",
      "Processing complete.\n",
      "Output saved in: data/education/processed/2_education_hyde.csv\n"
     ]
    }
   ],
   "source": [
    "# Using HyDE\n",
    "populate_answers(\"education\", edu_sampled_df, QueryTransformationType.HYDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b971836b-76a6-4bc6-af34-afe8124f22d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from ..\\models\\embeddings\\squad_faiss_index_new.idx...\n",
      "Progress saved at question 5/929.\n",
      "Progress saved at question 10/929.\n",
      "Progress saved at question 15/929.\n",
      "Progress saved at question 20/929.\n",
      "Progress saved at question 25/929.\n",
      "Progress saved at question 30/929.\n",
      "Progress saved at question 35/929.\n",
      "Progress saved at question 40/929.\n",
      "Progress saved at question 45/929.\n",
      "Progress saved at question 50/929.\n",
      "Progress saved at question 55/929.\n",
      "Progress saved at question 60/929.\n",
      "Progress saved at question 65/929.\n",
      "Progress saved at question 70/929.\n",
      "Progress saved at question 75/929.\n",
      "Progress saved at question 80/929.\n",
      "Progress saved at question 85/929.\n",
      "Progress saved at question 90/929.\n",
      "Progress saved at question 95/929.\n",
      "Progress saved at question 100/929.\n",
      "Progress saved at question 105/929.\n",
      "Progress saved at question 110/929.\n",
      "Progress saved at question 115/929.\n",
      "Progress saved at question 120/929.\n",
      "Progress saved at question 125/929.\n",
      "Progress saved at question 130/929.\n",
      "Progress saved at question 135/929.\n",
      "Progress saved at question 140/929.\n",
      "Progress saved at question 145/929.\n",
      "Progress saved at question 150/929.\n",
      "Progress saved at question 155/929.\n",
      "Progress saved at question 160/929.\n",
      "Progress saved at question 165/929.\n",
      "Progress saved at question 170/929.\n",
      "Progress saved at question 175/929.\n",
      "Progress saved at question 180/929.\n",
      "Progress saved at question 185/929.\n",
      "Progress saved at question 190/929.\n",
      "Progress saved at question 195/929.\n",
      "Progress saved at question 200/929.\n",
      "Progress saved at question 205/929.\n",
      "Progress saved at question 210/929.\n",
      "Progress saved at question 215/929.\n",
      "Progress saved at question 220/929.\n",
      "Progress saved at question 225/929.\n",
      "Progress saved at question 230/929.\n",
      "Progress saved at question 235/929.\n",
      "Progress saved at question 240/929.\n",
      "Progress saved at question 245/929.\n",
      "Progress saved at question 250/929.\n",
      "Progress saved at question 255/929.\n",
      "Progress saved at question 260/929.\n",
      "Progress saved at question 265/929.\n",
      "Progress saved at question 270/929.\n",
      "Progress saved at question 275/929.\n",
      "Progress saved at question 280/929.\n",
      "Progress saved at question 285/929.\n",
      "Progress saved at question 290/929.\n",
      "Progress saved at question 295/929.\n",
      "Progress saved at question 300/929.\n",
      "Progress saved at question 305/929.\n",
      "Progress saved at question 310/929.\n",
      "Progress saved at question 315/929.\n",
      "Progress saved at question 320/929.\n",
      "Progress saved at question 325/929.\n",
      "Progress saved at question 330/929.\n",
      "Progress saved at question 335/929.\n",
      "Progress saved at question 340/929.\n",
      "Progress saved at question 345/929.\n",
      "Progress saved at question 350/929.\n",
      "Progress saved at question 355/929.\n",
      "Progress saved at question 360/929.\n",
      "Progress saved at question 365/929.\n",
      "Progress saved at question 370/929.\n",
      "Progress saved at question 375/929.\n",
      "Progress saved at question 380/929.\n",
      "Progress saved at question 385/929.\n",
      "Progress saved at question 390/929.\n",
      "Progress saved at question 395/929.\n",
      "Progress saved at question 400/929.\n",
      "Progress saved at question 405/929.\n",
      "Progress saved at question 410/929.\n",
      "Progress saved at question 415/929.\n",
      "Progress saved at question 420/929.\n",
      "Progress saved at question 425/929.\n",
      "Progress saved at question 430/929.\n",
      "Progress saved at question 435/929.\n",
      "Progress saved at question 440/929.\n",
      "Progress saved at question 445/929.\n",
      "Progress saved at question 450/929.\n",
      "Progress saved at question 455/929.\n",
      "Progress saved at question 460/929.\n",
      "Progress saved at question 465/929.\n",
      "Progress saved at question 470/929.\n",
      "Progress saved at question 475/929.\n",
      "Progress saved at question 480/929.\n",
      "Progress saved at question 485/929.\n",
      "Progress saved at question 490/929.\n",
      "Progress saved at question 495/929.\n",
      "Progress saved at question 500/929.\n",
      "Progress saved at question 505/929.\n",
      "Progress saved at question 510/929.\n",
      "Progress saved at question 515/929.\n",
      "Progress saved at question 520/929.\n",
      "Progress saved at question 525/929.\n",
      "Progress saved at question 530/929.\n",
      "Progress saved at question 535/929.\n",
      "Progress saved at question 540/929.\n",
      "Progress saved at question 545/929.\n",
      "Progress saved at question 550/929.\n",
      "Progress saved at question 555/929.\n",
      "Progress saved at question 560/929.\n",
      "Progress saved at question 565/929.\n",
      "Progress saved at question 570/929.\n",
      "Progress saved at question 575/929.\n",
      "Progress saved at question 580/929.\n",
      "Progress saved at question 585/929.\n",
      "Progress saved at question 590/929.\n",
      "Progress saved at question 595/929.\n",
      "Progress saved at question 600/929.\n",
      "Progress saved at question 605/929.\n",
      "Progress saved at question 610/929.\n",
      "Progress saved at question 615/929.\n",
      "Progress saved at question 620/929.\n",
      "Progress saved at question 625/929.\n",
      "Progress saved at question 630/929.\n",
      "Progress saved at question 635/929.\n",
      "Progress saved at question 640/929.\n",
      "Progress saved at question 645/929.\n",
      "Progress saved at question 650/929.\n",
      "Progress saved at question 655/929.\n",
      "Progress saved at question 660/929.\n",
      "Progress saved at question 665/929.\n",
      "Progress saved at question 670/929.\n",
      "Progress saved at question 675/929.\n",
      "Progress saved at question 680/929.\n",
      "Progress saved at question 685/929.\n",
      "Progress saved at question 690/929.\n",
      "Progress saved at question 695/929.\n",
      "Progress saved at question 700/929.\n",
      "Progress saved at question 705/929.\n",
      "Progress saved at question 710/929.\n",
      "Progress saved at question 715/929.\n",
      "Progress saved at question 720/929.\n",
      "Progress saved at question 725/929.\n",
      "Progress saved at question 730/929.\n",
      "Progress saved at question 735/929.\n",
      "Progress saved at question 740/929.\n",
      "Progress saved at question 745/929.\n",
      "Progress saved at question 750/929.\n",
      "Progress saved at question 755/929.\n",
      "Progress saved at question 760/929.\n",
      "Progress saved at question 765/929.\n",
      "Progress saved at question 770/929.\n",
      "Progress saved at question 775/929.\n",
      "Progress saved at question 780/929.\n",
      "Progress saved at question 785/929.\n",
      "Progress saved at question 790/929.\n",
      "Progress saved at question 795/929.\n",
      "Progress saved at question 800/929.\n",
      "Progress saved at question 805/929.\n",
      "Progress saved at question 810/929.\n",
      "Progress saved at question 815/929.\n",
      "Progress saved at question 820/929.\n",
      "Progress saved at question 825/929.\n",
      "Progress saved at question 830/929.\n",
      "Progress saved at question 835/929.\n",
      "Progress saved at question 840/929.\n",
      "Progress saved at question 845/929.\n",
      "Progress saved at question 850/929.\n",
      "Progress saved at question 855/929.\n",
      "Progress saved at question 860/929.\n",
      "Progress saved at question 865/929.\n",
      "Progress saved at question 870/929.\n",
      "Progress saved at question 875/929.\n",
      "Progress saved at question 880/929.\n",
      "Progress saved at question 885/929.\n",
      "Progress saved at question 890/929.\n",
      "Progress saved at question 895/929.\n",
      "Progress saved at question 900/929.\n",
      "Progress saved at question 905/929.\n",
      "Progress saved at question 910/929.\n",
      "Progress saved at question 915/929.\n",
      "Progress saved at question 920/929.\n",
      "Progress saved at question 925/929.\n",
      "Progress saved at question 929/929.\n",
      "Processing complete.\n",
      "Output saved in: data/education/processed/2_education_compression.csv\n"
     ]
    }
   ],
   "source": [
    "# Using compression\n",
    "populate_answers(\"education\", edu_sampled_df, QueryTransformationType.COMPRESSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc0b7f-18a7-4e1f-ba74-7a49356bbe3d",
   "metadata": {},
   "source": [
    "### Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d97d62a9-3482-4a62-9ce0-c63f273abb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emir\\AppData\\Local\\Temp\\ipykernel_5576\\3075347949.py:47: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby('topic_lda', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Perform stratified sampling from testing dataset\n",
    "hc_sampled_df = stratified_sampling('healthcare', sample_size=465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7769890-f49b-43e7-891e-a0d38067f84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(930, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87234aaf-4753-4cb6-a221-3b019f509dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>topic_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The etiology of benign prostatic hypertrophy (...</td>\n",
       "      <td>Does prostate-specific antigen induce prolifer...</td>\n",
       "      <td>These findings show that PSA is able to induce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Platelet-rich plasma is characterized by conta...</td>\n",
       "      <td>Does platelet-rich plasma suppress osteoclasto...</td>\n",
       "      <td>Under our experimental conditions, platelet-ri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To investigate the effects of intravenous pent...</td>\n",
       "      <td>Does tilidine affect human sphincter of Oddi m...</td>\n",
       "      <td>In contrast to 30 mg of pentazocine, 50 mg of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animals respond to inflammation by suppressing...</td>\n",
       "      <td>Is expression of myeloid differentiation facto...</td>\n",
       "      <td>Sickness behavior is mediated by MyD88 and is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To investigate the role of Rho A and Rho-kinas...</td>\n",
       "      <td>Does inhibition of Rho-kinase protect the hear...</td>\n",
       "      <td>These results suggest that Rho-kinase plays a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  The etiology of benign prostatic hypertrophy (...   \n",
       "1  Platelet-rich plasma is characterized by conta...   \n",
       "2  To investigate the effects of intravenous pent...   \n",
       "3  Animals respond to inflammation by suppressing...   \n",
       "4  To investigate the role of Rho A and Rho-kinas...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Does prostate-specific antigen induce prolifer...   \n",
       "1  Does platelet-rich plasma suppress osteoclasto...   \n",
       "2  Does tilidine affect human sphincter of Oddi m...   \n",
       "3  Is expression of myeloid differentiation facto...   \n",
       "4  Does inhibition of Rho-kinase protect the hear...   \n",
       "\n",
       "                                              answer  topic_lda  \n",
       "0  These findings show that PSA is able to induce...          0  \n",
       "1  Under our experimental conditions, platelet-ri...          0  \n",
       "2  In contrast to 30 mg of pentazocine, 50 mg of ...          0  \n",
       "3  Sickness behavior is mediated by MyD88 and is ...          0  \n",
       "4  These results suggest that Rho-kinase plays a ...          0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7509003-f19e-46d1-8a9f-b32ae181d0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_lda\n",
       "0    465\n",
       "1    465\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_sampled_df['topic_lda'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c633ddcf-c61d-41c9-a33c-f90d34561dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_sampled_df.to_csv('data/healthcare/processed/1_healthcare_noanswer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74327447-5857-43ca-9c4b-0eac4a46b9db",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ba313f6-d9d0-4231-a48e-eb9e9aaeae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the healthcare testing dataset\n",
    "hc_sampled_df = pd.read_csv('data/healthcare/processed/1_healthcare_noanswer.csv', nrows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1bcff7-d605-428f-b749-e1f439b67660",
   "metadata": {},
   "source": [
    "#### Query transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd0387cf-7d76-4521-9be3-6574c02576c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from ..\\models\\embeddings\\pubmedqa_faiss_index_subset.idx...\n",
      "Progress saved at question 5/5.\n",
      "Processing complete.\n",
      "Output saved in: data/healthcare/processed/2_healthcare_baseline.csv\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "populate_answers(\"healthcare\", hc_sampled_df, QueryTransformationType.BASELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba5e69da-456a-4732-a85b-0a0c3251a2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from ..\\models\\embeddings\\pubmedqa_faiss_index_subset.idx...\n",
      "Progress saved at question 5/930.\n",
      "Progress saved at question 10/930.\n",
      "Progress saved at question 15/930.\n",
      "Progress saved at question 20/930.\n",
      "Progress saved at question 25/930.\n",
      "Progress saved at question 30/930.\n",
      "Progress saved at question 35/930.\n",
      "Progress saved at question 40/930.\n",
      "Progress saved at question 45/930.\n",
      "Progress saved at question 50/930.\n",
      "Progress saved at question 55/930.\n",
      "Progress saved at question 60/930.\n",
      "Progress saved at question 65/930.\n",
      "Progress saved at question 70/930.\n",
      "Progress saved at question 75/930.\n",
      "Progress saved at question 80/930.\n",
      "Progress saved at question 85/930.\n",
      "Progress saved at question 90/930.\n",
      "Progress saved at question 95/930.\n",
      "Progress saved at question 100/930.\n",
      "Progress saved at question 105/930.\n",
      "Progress saved at question 110/930.\n",
      "Progress saved at question 115/930.\n",
      "Progress saved at question 120/930.\n",
      "Progress saved at question 125/930.\n",
      "Progress saved at question 130/930.\n",
      "Progress saved at question 135/930.\n",
      "Progress saved at question 140/930.\n",
      "Progress saved at question 145/930.\n",
      "Progress saved at question 150/930.\n",
      "Progress saved at question 155/930.\n",
      "Progress saved at question 160/930.\n",
      "Progress saved at question 165/930.\n",
      "Progress saved at question 170/930.\n",
      "Progress saved at question 175/930.\n",
      "Progress saved at question 180/930.\n",
      "Progress saved at question 185/930.\n",
      "Progress saved at question 190/930.\n",
      "Progress saved at question 195/930.\n",
      "Progress saved at question 200/930.\n",
      "Progress saved at question 205/930.\n",
      "Progress saved at question 210/930.\n",
      "Progress saved at question 215/930.\n",
      "Progress saved at question 220/930.\n",
      "Progress saved at question 225/930.\n",
      "Progress saved at question 230/930.\n",
      "Progress saved at question 235/930.\n",
      "Progress saved at question 240/930.\n",
      "Progress saved at question 245/930.\n",
      "Progress saved at question 250/930.\n",
      "Progress saved at question 255/930.\n",
      "Progress saved at question 260/930.\n",
      "Progress saved at question 265/930.\n",
      "Progress saved at question 270/930.\n",
      "Progress saved at question 275/930.\n",
      "Progress saved at question 280/930.\n",
      "Progress saved at question 285/930.\n",
      "Progress saved at question 290/930.\n",
      "Progress saved at question 295/930.\n",
      "Progress saved at question 300/930.\n",
      "Progress saved at question 305/930.\n",
      "Progress saved at question 310/930.\n",
      "Progress saved at question 315/930.\n",
      "Progress saved at question 320/930.\n",
      "Progress saved at question 325/930.\n",
      "Progress saved at question 330/930.\n",
      "Progress saved at question 335/930.\n",
      "Progress saved at question 340/930.\n",
      "Progress saved at question 345/930.\n",
      "Progress saved at question 350/930.\n",
      "Progress saved at question 355/930.\n",
      "Progress saved at question 360/930.\n",
      "Progress saved at question 365/930.\n",
      "Progress saved at question 370/930.\n",
      "Progress saved at question 375/930.\n",
      "Progress saved at question 380/930.\n",
      "Progress saved at question 385/930.\n",
      "Progress saved at question 390/930.\n",
      "Progress saved at question 395/930.\n",
      "Progress saved at question 400/930.\n",
      "Progress saved at question 405/930.\n",
      "Progress saved at question 410/930.\n",
      "Progress saved at question 415/930.\n",
      "Progress saved at question 420/930.\n",
      "Progress saved at question 425/930.\n",
      "Progress saved at question 430/930.\n",
      "Progress saved at question 435/930.\n",
      "Progress saved at question 440/930.\n",
      "Progress saved at question 445/930.\n",
      "Progress saved at question 450/930.\n",
      "Progress saved at question 455/930.\n",
      "Progress saved at question 460/930.\n",
      "Progress saved at question 465/930.\n",
      "Progress saved at question 470/930.\n",
      "Progress saved at question 475/930.\n",
      "Progress saved at question 480/930.\n",
      "Progress saved at question 485/930.\n",
      "Progress saved at question 490/930.\n",
      "Progress saved at question 495/930.\n",
      "Progress saved at question 500/930.\n",
      "Progress saved at question 505/930.\n",
      "Progress saved at question 510/930.\n",
      "Progress saved at question 515/930.\n",
      "Progress saved at question 520/930.\n",
      "Progress saved at question 525/930.\n",
      "Progress saved at question 530/930.\n",
      "Progress saved at question 535/930.\n",
      "Progress saved at question 540/930.\n",
      "Progress saved at question 545/930.\n",
      "Progress saved at question 550/930.\n",
      "Progress saved at question 555/930.\n",
      "Progress saved at question 560/930.\n",
      "Progress saved at question 565/930.\n",
      "Progress saved at question 570/930.\n",
      "Progress saved at question 575/930.\n",
      "Progress saved at question 580/930.\n",
      "Progress saved at question 585/930.\n",
      "Progress saved at question 590/930.\n",
      "Progress saved at question 595/930.\n",
      "Progress saved at question 600/930.\n",
      "Progress saved at question 605/930.\n",
      "Progress saved at question 610/930.\n",
      "Progress saved at question 615/930.\n",
      "Progress saved at question 620/930.\n",
      "Progress saved at question 625/930.\n",
      "Progress saved at question 630/930.\n",
      "Progress saved at question 635/930.\n",
      "Progress saved at question 640/930.\n",
      "Progress saved at question 645/930.\n",
      "Progress saved at question 650/930.\n",
      "Progress saved at question 655/930.\n",
      "Progress saved at question 660/930.\n",
      "Progress saved at question 665/930.\n",
      "Progress saved at question 670/930.\n",
      "Progress saved at question 675/930.\n",
      "Progress saved at question 680/930.\n",
      "Progress saved at question 685/930.\n",
      "Progress saved at question 690/930.\n",
      "Progress saved at question 695/930.\n",
      "Progress saved at question 700/930.\n",
      "Progress saved at question 705/930.\n",
      "Progress saved at question 710/930.\n",
      "Progress saved at question 715/930.\n",
      "Progress saved at question 720/930.\n",
      "Progress saved at question 725/930.\n",
      "Progress saved at question 730/930.\n",
      "Progress saved at question 735/930.\n",
      "Progress saved at question 740/930.\n",
      "Progress saved at question 745/930.\n",
      "Progress saved at question 750/930.\n",
      "Progress saved at question 755/930.\n",
      "Progress saved at question 760/930.\n",
      "Progress saved at question 765/930.\n",
      "Progress saved at question 770/930.\n",
      "Progress saved at question 775/930.\n",
      "Progress saved at question 780/930.\n",
      "Progress saved at question 785/930.\n",
      "Progress saved at question 790/930.\n",
      "Progress saved at question 795/930.\n",
      "Progress saved at question 800/930.\n",
      "Progress saved at question 805/930.\n",
      "Progress saved at question 810/930.\n",
      "Progress saved at question 815/930.\n",
      "Progress saved at question 820/930.\n",
      "Progress saved at question 825/930.\n",
      "Progress saved at question 830/930.\n",
      "Progress saved at question 835/930.\n",
      "Progress saved at question 840/930.\n",
      "Progress saved at question 845/930.\n",
      "Progress saved at question 850/930.\n",
      "Progress saved at question 855/930.\n",
      "Progress saved at question 860/930.\n",
      "Progress saved at question 865/930.\n",
      "Progress saved at question 870/930.\n",
      "Progress saved at question 875/930.\n",
      "Progress saved at question 880/930.\n",
      "Progress saved at question 885/930.\n",
      "Progress saved at question 890/930.\n",
      "Progress saved at question 895/930.\n",
      "Progress saved at question 900/930.\n",
      "Progress saved at question 905/930.\n",
      "Progress saved at question 910/930.\n",
      "Progress saved at question 915/930.\n",
      "Progress saved at question 920/930.\n",
      "Progress saved at question 925/930.\n",
      "Progress saved at question 930/930.\n",
      "Processing complete.\n",
      "Output saved in: data/healthcare/processed/2_healthcare_cookbook.csv\n"
     ]
    }
   ],
   "source": [
    "# Using cookbook rewriting\n",
    "populate_answers(\"healthcare\", hc_sampled_df, QueryTransformationType.COOKBOOK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7dee1050-eab9-47c0-ab5d-0ef6c439baf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from ..\\models\\embeddings\\pubmedqa_faiss_index_subset.idx...\n",
      "Progress saved at question 5/930.\n",
      "Progress saved at question 10/930.\n",
      "Progress saved at question 15/930.\n",
      "Progress saved at question 20/930.\n",
      "Progress saved at question 25/930.\n",
      "Progress saved at question 30/930.\n",
      "Progress saved at question 35/930.\n",
      "Progress saved at question 40/930.\n",
      "Progress saved at question 45/930.\n",
      "Progress saved at question 50/930.\n",
      "Progress saved at question 55/930.\n",
      "Progress saved at question 60/930.\n",
      "Progress saved at question 65/930.\n",
      "Progress saved at question 70/930.\n",
      "Progress saved at question 75/930.\n",
      "Progress saved at question 80/930.\n",
      "Progress saved at question 85/930.\n",
      "Progress saved at question 90/930.\n",
      "Progress saved at question 95/930.\n",
      "Progress saved at question 100/930.\n",
      "Progress saved at question 105/930.\n",
      "Progress saved at question 110/930.\n",
      "Progress saved at question 115/930.\n",
      "Progress saved at question 120/930.\n",
      "Progress saved at question 125/930.\n",
      "Progress saved at question 130/930.\n",
      "Progress saved at question 135/930.\n",
      "Progress saved at question 140/930.\n",
      "Progress saved at question 145/930.\n",
      "Progress saved at question 150/930.\n",
      "Progress saved at question 155/930.\n",
      "Progress saved at question 160/930.\n",
      "Progress saved at question 165/930.\n",
      "Progress saved at question 170/930.\n",
      "Progress saved at question 175/930.\n",
      "Progress saved at question 180/930.\n",
      "Progress saved at question 185/930.\n",
      "Progress saved at question 190/930.\n",
      "Progress saved at question 195/930.\n",
      "Progress saved at question 200/930.\n",
      "Progress saved at question 205/930.\n",
      "Progress saved at question 210/930.\n",
      "Progress saved at question 215/930.\n",
      "Progress saved at question 220/930.\n",
      "Progress saved at question 225/930.\n",
      "Progress saved at question 230/930.\n",
      "Progress saved at question 235/930.\n",
      "Progress saved at question 240/930.\n",
      "Progress saved at question 245/930.\n",
      "Progress saved at question 250/930.\n",
      "Progress saved at question 255/930.\n",
      "Progress saved at question 260/930.\n",
      "Progress saved at question 265/930.\n",
      "Progress saved at question 270/930.\n",
      "Progress saved at question 275/930.\n",
      "Progress saved at question 280/930.\n",
      "Progress saved at question 285/930.\n",
      "Progress saved at question 290/930.\n",
      "Progress saved at question 295/930.\n",
      "Progress saved at question 300/930.\n",
      "Progress saved at question 305/930.\n",
      "Progress saved at question 310/930.\n",
      "Progress saved at question 315/930.\n",
      "Progress saved at question 320/930.\n",
      "Progress saved at question 325/930.\n",
      "Progress saved at question 330/930.\n",
      "Progress saved at question 335/930.\n",
      "Progress saved at question 340/930.\n",
      "Progress saved at question 345/930.\n",
      "Progress saved at question 350/930.\n",
      "Progress saved at question 355/930.\n",
      "Progress saved at question 360/930.\n",
      "Progress saved at question 365/930.\n",
      "Progress saved at question 370/930.\n",
      "Progress saved at question 375/930.\n",
      "Progress saved at question 380/930.\n",
      "Progress saved at question 385/930.\n",
      "Progress saved at question 390/930.\n",
      "Progress saved at question 395/930.\n",
      "Progress saved at question 400/930.\n",
      "Progress saved at question 405/930.\n",
      "Progress saved at question 410/930.\n",
      "Progress saved at question 415/930.\n",
      "Progress saved at question 420/930.\n",
      "Progress saved at question 425/930.\n",
      "Progress saved at question 430/930.\n",
      "Progress saved at question 435/930.\n",
      "Progress saved at question 440/930.\n",
      "Progress saved at question 445/930.\n",
      "Progress saved at question 450/930.\n",
      "Progress saved at question 455/930.\n",
      "Progress saved at question 460/930.\n",
      "Progress saved at question 465/930.\n",
      "Progress saved at question 470/930.\n",
      "Progress saved at question 475/930.\n",
      "Progress saved at question 480/930.\n",
      "Progress saved at question 485/930.\n",
      "Progress saved at question 490/930.\n",
      "Progress saved at question 495/930.\n",
      "Progress saved at question 500/930.\n",
      "Progress saved at question 505/930.\n",
      "Progress saved at question 510/930.\n",
      "Progress saved at question 515/930.\n",
      "Progress saved at question 520/930.\n",
      "Progress saved at question 525/930.\n",
      "Progress saved at question 530/930.\n",
      "Progress saved at question 535/930.\n",
      "Progress saved at question 540/930.\n",
      "Progress saved at question 545/930.\n",
      "Progress saved at question 550/930.\n",
      "Progress saved at question 555/930.\n",
      "Progress saved at question 560/930.\n",
      "Progress saved at question 565/930.\n",
      "Progress saved at question 570/930.\n",
      "Progress saved at question 575/930.\n",
      "Progress saved at question 580/930.\n",
      "Progress saved at question 585/930.\n",
      "Progress saved at question 590/930.\n",
      "Progress saved at question 595/930.\n",
      "Progress saved at question 600/930.\n",
      "Progress saved at question 605/930.\n",
      "Progress saved at question 610/930.\n",
      "Progress saved at question 615/930.\n",
      "Progress saved at question 620/930.\n",
      "Progress saved at question 625/930.\n",
      "Progress saved at question 630/930.\n",
      "Progress saved at question 635/930.\n",
      "Progress saved at question 640/930.\n",
      "Progress saved at question 645/930.\n",
      "Progress saved at question 650/930.\n",
      "Progress saved at question 655/930.\n",
      "Progress saved at question 660/930.\n",
      "Progress saved at question 665/930.\n",
      "Progress saved at question 670/930.\n",
      "Progress saved at question 675/930.\n",
      "Progress saved at question 680/930.\n",
      "Progress saved at question 685/930.\n",
      "Progress saved at question 690/930.\n",
      "Progress saved at question 695/930.\n",
      "Progress saved at question 700/930.\n",
      "Progress saved at question 705/930.\n",
      "Progress saved at question 710/930.\n",
      "Progress saved at question 715/930.\n",
      "Progress saved at question 720/930.\n",
      "Progress saved at question 725/930.\n",
      "Progress saved at question 730/930.\n",
      "Progress saved at question 735/930.\n",
      "Progress saved at question 740/930.\n",
      "Progress saved at question 745/930.\n",
      "Progress saved at question 750/930.\n",
      "Progress saved at question 755/930.\n",
      "Progress saved at question 760/930.\n",
      "Progress saved at question 765/930.\n",
      "Progress saved at question 770/930.\n",
      "Progress saved at question 775/930.\n",
      "Progress saved at question 780/930.\n",
      "Progress saved at question 785/930.\n",
      "Progress saved at question 790/930.\n",
      "Progress saved at question 795/930.\n",
      "Progress saved at question 800/930.\n",
      "Progress saved at question 805/930.\n",
      "Progress saved at question 810/930.\n",
      "Progress saved at question 815/930.\n",
      "Progress saved at question 820/930.\n",
      "Progress saved at question 825/930.\n",
      "Progress saved at question 830/930.\n",
      "Progress saved at question 835/930.\n",
      "Progress saved at question 840/930.\n",
      "Progress saved at question 845/930.\n",
      "Progress saved at question 850/930.\n",
      "Progress saved at question 855/930.\n",
      "Progress saved at question 860/930.\n",
      "Progress saved at question 865/930.\n",
      "Progress saved at question 870/930.\n",
      "Progress saved at question 875/930.\n",
      "Progress saved at question 880/930.\n",
      "Progress saved at question 885/930.\n",
      "Progress saved at question 890/930.\n",
      "Progress saved at question 895/930.\n",
      "Progress saved at question 900/930.\n",
      "Progress saved at question 905/930.\n",
      "Progress saved at question 910/930.\n",
      "Progress saved at question 915/930.\n",
      "Progress saved at question 920/930.\n",
      "Progress saved at question 925/930.\n",
      "Progress saved at question 930/930.\n",
      "Processing complete.\n",
      "Output saved in: data/healthcare/processed/2_healthcare_hyde.csv\n"
     ]
    }
   ],
   "source": [
    "# Using HyDE\n",
    "populate_answers(\"healthcare\", hc_sampled_df, QueryTransformationType.HYDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef3a5a95-96df-46b1-83b4-b15f9c3af6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from ..\\models\\embeddings\\pubmedqa_faiss_index_subset.idx...\n",
      "Progress saved at question 5/5.\n",
      "Processing complete.\n",
      "Output saved in: data/healthcare/processed/2_healthcare_compression.csv\n"
     ]
    }
   ],
   "source": [
    "# Using compression\n",
    "populate_answers(\"healthcare\", hc_sampled_df, QueryTransformationType.COMPRESSION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
